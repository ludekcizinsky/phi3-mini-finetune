{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preference Data\n",
                "\n",
                "This notebook prepares the preference data for MCQ."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "---\n",
                "\n",
                "Let's install some necessary dependencies and set global variables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import autorootcwd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%reload_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modules\n",
                "import re\n",
                "import pandas as pd\n",
                "from pprint import pprint\n",
                "\n",
                "from src.data.datasets.preference import PreferenceData"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train: 21390, Val: 5348\n"
                    ]
                }
            ],
            "source": [
                "train = PreferenceData(split=\"train\", filtering_strategy=\"none\")\n",
                "val = PreferenceData(split=\"val\", filtering_strategy=\"none\")\n",
                "\n",
                "print(f\"Train: {len(train)}, Val: {len(val)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Find MCQ Question\n",
                "\n",
                "First, we need to find the MCQ question from the preference data. Although the `question` and `question_options` key have been merged into the `question_complete` (called `prompt` in the `PreferenceData`), we can pretty easily extract the MCQ question because the available options are always formatted in the same way:\n",
                "\n",
                "* The question is followed by the string `Options:\\n`\n",
                "* It then lists the options `A. [Option A]\\n`, `B. [Option B]`, ...\n",
                "* Most MCQ questions have a four answer options, but some are also True/ False questions\n",
                "\n",
                "We can simply write a Regex pattern to only retain the MCQ question."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {},
            "outputs": [],
            "source": [
                "def is_mcq(question: str):\n",
                "    \"\"\"\n",
                "    Helper utility to check if a question is a multiple choice question.\n",
                "    In the preference dataset, multiple choice questions are formatted as follows:\n",
                "\n",
                "    ```\n",
                "    Options:\n",
                "    A. Option 1\n",
                "    B. Option 2\n",
                "    ...\n",
                "    ```\n",
                "\n",
                "    Args:\n",
                "        question (str): The question to check.\n",
                "\n",
                "    Returns:\n",
                "        bool: True if the question is a multiple choice question, False otherwise.\n",
                "    \"\"\"\n",
                "    pattern = r'Options:\\n(?:[A-D]\\..+\\n)+'\n",
                "    return bool(re.search(pattern, question))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train: 11005 (51.4%), Val: 2778 (51.9%)\n"
                    ]
                }
            ],
            "source": [
                "train_mcq = train.filter(is_mcq, input_columns=\"prompt\")\n",
                "val_mcq = val.filter(is_mcq, input_columns=\"prompt\")\n",
                "\n",
                "print(f\"Train: {len(train_mcq)} ({100*(len(train_mcq)/ len(train)):.1f}%), Val: {len(val_mcq)} ({100*(len(val_mcq)/ len(val)):.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Find Answer Key\n",
                "\n",
                "Next, we need to find the correct response from the preferred answer (`chosen`) and the non-preferred answer (`rejected`) in the multiple choice questions. If we do SFT finetuning we will only use the chosen response, but we might consider doing DPO training on the MCQ formatted dataset.\n",
                "\n",
                "I noticed the following in the answers:\n",
                "* Sometimes, the model answers with digits (1-4), or strings like `Option 1` instead of letters.\n",
                "* Sometimes, the model only gives the answer in natural language without referring to the question options\n",
                "* ...\n",
                "\n",
                "Given this, we will likely have to fall back to an LLM to extract the correct response from the preference pair and map back to the correct letter (A-D) from the question answers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Use LLM to extract the correct answer for MCQs."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "mnlp-project",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
